{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Veri kümesindeki notların ağırlıklı ortalamasını içeren bir değişken oluşturun. Dördüncü sınıftaki öğrencilerin sayısı ile sekizinci sınıftaki öğrencilerin sayısı farklı. Bu yüzden ağırlıklı ortalamaya ihtiyacınız olacak!\n",
    "\n",
    "2.Yeni oluşturduğunuz değişken ile harcama çeşitlerinin korelasyonu nedir? Hangi harcama kaleminin korelasyonu diğerlerine göre fazladır?\n",
    "\n",
    "3.Şimdi dört harcama kalemi için Temel Bileşenler Analizi (PCA) uygulayın! Toplam varyansın ne kadarı ilk bileşen tarafından açıklanabilmektedir?\n",
    "\n",
    "4.Oluşturduğunuz genel not ortalaması ve ilk temel bileşen arasındaki korelasyon nedir?\n",
    "\n",
    "5.Modeliniz için en uygun değişkenleri seçmeniz gerektiğinde, harcama kalemlerinin yerine ilk temel değişkenleri tercih eder miydiniz? Neden?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2678885.0</td>\n",
       "      <td>304177.0</td>\n",
       "      <td>1659028.0</td>\n",
       "      <td>715680.0</td>\n",
       "      <td>2653798.0</td>\n",
       "      <td>1481703.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.0</td>\n",
       "      <td>58025.0</td>\n",
       "      <td>41167.0</td>\n",
       "      <td>471564.0</td>\n",
       "      <td>196386.0</td>\n",
       "      <td>676174.0</td>\n",
       "      <td>208.327876</td>\n",
       "      <td>252.187522</td>\n",
       "      <td>207.963517</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1049591.0</td>\n",
       "      <td>106780.0</td>\n",
       "      <td>720711.0</td>\n",
       "      <td>222100.0</td>\n",
       "      <td>972488.0</td>\n",
       "      <td>498362.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.0</td>\n",
       "      <td>8789.0</td>\n",
       "      <td>6714.0</td>\n",
       "      <td>79117.0</td>\n",
       "      <td>30847.0</td>\n",
       "      <td>112335.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>258.859712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3258079.0</td>\n",
       "      <td>297888.0</td>\n",
       "      <td>1369815.0</td>\n",
       "      <td>1590376.0</td>\n",
       "      <td>3401580.0</td>\n",
       "      <td>1435908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.0</td>\n",
       "      <td>49081.0</td>\n",
       "      <td>37410.0</td>\n",
       "      <td>437127.0</td>\n",
       "      <td>175210.0</td>\n",
       "      <td>614881.0</td>\n",
       "      <td>215.253932</td>\n",
       "      <td>265.366278</td>\n",
       "      <td>206.212716</td>\n",
       "      <td>262.169895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1711959.0</td>\n",
       "      <td>178571.0</td>\n",
       "      <td>958785.0</td>\n",
       "      <td>574603.0</td>\n",
       "      <td>1743022.0</td>\n",
       "      <td>964323.0</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.0</td>\n",
       "      <td>36011.0</td>\n",
       "      <td>27651.0</td>\n",
       "      <td>281338.0</td>\n",
       "      <td>123113.0</td>\n",
       "      <td>405259.0</td>\n",
       "      <td>210.206028</td>\n",
       "      <td>256.312090</td>\n",
       "      <td>208.634458</td>\n",
       "      <td>264.619665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26260025.0</td>\n",
       "      <td>2072470.0</td>\n",
       "      <td>16546514.0</td>\n",
       "      <td>7641041.0</td>\n",
       "      <td>27138832.0</td>\n",
       "      <td>14358922.0</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.0</td>\n",
       "      <td>363296.0</td>\n",
       "      <td>270675.0</td>\n",
       "      <td>3286034.0</td>\n",
       "      <td>1372011.0</td>\n",
       "      <td>4717112.0</td>\n",
       "      <td>208.398961</td>\n",
       "      <td>260.892247</td>\n",
       "      <td>196.764414</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     NaN      2678885.0         304177.0   \n",
       "1      1992_ALASKA      ALASKA  1992     NaN      1049591.0         106780.0   \n",
       "2     1992_ARIZONA     ARIZONA  1992     NaN      3258079.0         297888.0   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     NaN      1711959.0         178571.0   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     NaN     26260025.0        2072470.0   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0      1659028.0       715680.0          2653798.0                1481703.0   \n",
       "1       720711.0       222100.0           972488.0                 498362.0   \n",
       "2      1369815.0      1590376.0          3401580.0                1435908.0   \n",
       "3       958785.0       574603.0          1743022.0                 964323.0   \n",
       "4     16546514.0      7641041.0         27138832.0               14358922.0   \n",
       "\n",
       "          ...           GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  \\\n",
       "0         ...              57948.0     58025.0      41167.0      471564.0   \n",
       "1         ...               9748.0      8789.0       6714.0       79117.0   \n",
       "2         ...              55433.0     49081.0      37410.0      437127.0   \n",
       "3         ...              34632.0     36011.0      27651.0      281338.0   \n",
       "4         ...             418418.0    363296.0     270675.0     3286034.0   \n",
       "\n",
       "   GRADES_9_12_G  GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  \\\n",
       "0       196386.0      676174.0        208.327876        252.187522   \n",
       "1        30847.0      112335.0               NaN               NaN   \n",
       "2       175210.0      614881.0        215.253932        265.366278   \n",
       "3       123113.0      405259.0        210.206028        256.312090   \n",
       "4      1372011.0     4717112.0        208.398961        260.892247   \n",
       "\n",
       "   AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0           207.963517                  NaN  \n",
       "1                  NaN           258.859712  \n",
       "2           206.212716           262.169895  \n",
       "3           208.634458           264.619665  \n",
       "4           196.764414                  NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_all2 =pd.read_csv(\"states_all.csv\")\n",
    "states_all2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Veri kümesindeki notların ağırlıklı ortalamasını içeren bir değişken oluşturun. Dördüncü sınıftaki öğrencilerin sayısı ile sekizinci sınıftaki öğrencilerin sayısı farklı. Bu yüzden ağırlıklı ortalamaya ihtiyacınız olacak!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_all2[\"overall_score\"] = (states_all2[\"GRADES_4_G\"]*((states_all2[\"AVG_MATH_4_SCORE\"] +\n",
    "states_all2[\"AVG_READING_4_SCORE\"])/2) + states_all2[\"GRADES_8_G\"] * ((states_all2[\"AVG_MATH_8_SCORE\"] + states_all2[\"AVG_READING_8_SCORE\"])/2))/(states_all2[\"GRADES_4_G\"] + states_all2[\"GRADES_8_G\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Yeni oluşturduğunuz değişken ile harcama çeşitlerinin korelasyonu nedir? Hangi harcama kaleminin korelasyonu diğerlerine göre fazladır? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991347</td>\n",
       "      <td>0.993314</td>\n",
       "      <td>0.946110</td>\n",
       "      <td>0.089937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <td>0.991347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976889</td>\n",
       "      <td>0.909340</td>\n",
       "      <td>0.103678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <td>0.993314</td>\n",
       "      <td>0.976889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953091</td>\n",
       "      <td>0.094103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <td>0.946110</td>\n",
       "      <td>0.909340</td>\n",
       "      <td>0.953091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_score</th>\n",
       "      <td>0.089937</td>\n",
       "      <td>0.103678</td>\n",
       "      <td>0.094103</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "TOTAL_EXPENDITURE                      1.000000                 0.991347   \n",
       "INSTRUCTION_EXPENDITURE                0.991347                 1.000000   \n",
       "SUPPORT_SERVICES_EXPENDITURE           0.993314                 0.976889   \n",
       "OTHER_EXPENDITURE                      0.946110                 0.909340   \n",
       "overall_score                          0.089937                 0.103678   \n",
       "\n",
       "                              SUPPORT_SERVICES_EXPENDITURE  OTHER_EXPENDITURE  \\\n",
       "TOTAL_EXPENDITURE                                 0.993314           0.946110   \n",
       "INSTRUCTION_EXPENDITURE                           0.976889           0.909340   \n",
       "SUPPORT_SERVICES_EXPENDITURE                      1.000000           0.953091   \n",
       "OTHER_EXPENDITURE                                 0.953091           1.000000   \n",
       "overall_score                                     0.094103           0.004678   \n",
       "\n",
       "                              overall_score  \n",
       "TOTAL_EXPENDITURE                  0.089937  \n",
       "INSTRUCTION_EXPENDITURE            0.103678  \n",
       "SUPPORT_SERVICES_EXPENDITURE       0.094103  \n",
       "OTHER_EXPENDITURE                  0.004678  \n",
       "overall_score                      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_all2[[\"TOTAL_EXPENDITURE\",\"INSTRUCTION_EXPENDITURE\", \"SUPPORT_SERVICES_EXPENDITURE\", \"OTHER_EXPENDITURE\",\"overall_score\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTRUCTION_EXPENDITURE ile en yuksek korelasyon goruyoruz. Diger harcamalarla ise dusuk bir korelasyon gorulmektedir. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Şimdi dört harcama kalemi için Temel Bileşenler Analizi (PCA) uygulayın! Toplam varyansın ne kadarı ilk bileşen tarafından açıklanabilmektedir?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BU SORUDA ASAGIDAKI GIBI OLAN STATES3 ILE DENEDIM OLMADI SONRA states_all_df OLUSTURUP DENEDIM'PRIMARY KEY \n",
    "#DEKI BIR DEGERIN FLOAT OLMASINDAN OTURU OLMADI\n",
    "# 29. SATIRDAKI GIBI DENEDIM BU DA OLMADI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1492 entries, 0 to 1491\n",
      "Data columns (total 4 columns):\n",
      "TOTAL_EXPENDITURE               1280 non-null float64\n",
      "INSTRUCTION_EXPENDITURE         1280 non-null float64\n",
      "SUPPORT_SERVICES_EXPENDITURE    1280 non-null float64\n",
      "OTHER_EXPENDITURE               1229 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 46.7 KB\n"
     ]
    }
   ],
   "source": [
    "states_all3 = states_all2[[\"TOTAL_EXPENDITURE\", \"INSTRUCTION_EXPENDITURE\", \"SUPPORT_SERVICES_EXPENDITURE\", \"OTHER_EXPENDITURE\"]]\n",
    "states_all3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pca = PCA(n_components=5)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X)\n",
    "\n",
    "P = eig_vec_cov[:, 0] \n",
    "\n",
    "Y = P.T.dot(Xt) \n",
    "\n",
    "print(\n",
    "    'Veri kümesindeki toplam varyans yüzdesi',\n",
    "    'Elle hesaplanan bileşen.\\n',\n",
    "    sklearn_pca.explained_variance_ratio_\n",
    ")\n",
    "\n",
    "# Compare the sklearn solution to ours – a perfect match.\n",
    "plt.plot(Y_sklearn[:, 0], Y, 'o')\n",
    "plt.title('Çözümlerin Karşılaştırılması')\n",
    "plt.ylabel('Sklearn Bileşeni 1')\n",
    "plt.xlabel('Elle Hesaplanan Bileşen 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
      "0             2653798.0                1481703.0   \n",
      "1              972488.0                 498362.0   \n",
      "2             3401580.0                1435908.0   \n",
      "3             1743022.0                 964323.0   \n",
      "4            27138832.0               14358922.0   \n",
      "5             3264826.0                1642466.0   \n",
      "6             3721338.0                2148041.0   \n",
      "7              638784.0                 372722.0   \n",
      "8              742893.0                 329160.0   \n",
      "9            11305642.0                5166374.0   \n",
      "10            5535942.0                3043984.0   \n",
      "11            1040121.0                 536115.0   \n",
      "12             886161.0                 473505.0   \n",
      "13            9850560.0                5010400.0   \n",
      "14            5182754.0                2598925.0   \n",
      "15            2795774.0                1446478.0   \n",
      "16            2234915.0                1165749.0   \n",
      "17            2518082.0                1343438.0   \n",
      "18            3362853.0                1888349.0   \n",
      "19            1228869.0                 685350.0   \n",
      "20            4698374.0                2628891.0   \n",
      "21            5245560.0                2751871.0   \n",
      "22           10170688.0                4681327.0   \n",
      "23            4981125.0                2534882.0   \n",
      "24            1691990.0                 956104.0   \n",
      "25            4197600.0                2168135.0   \n",
      "26             781009.0                 412219.0   \n",
      "27            1534046.0                 909159.0   \n",
      "28            1251651.0                 572623.0   \n",
      "29            1066647.0                 581123.0   \n",
      "...                 ...                      ...   \n",
      "1462                NaN                      NaN   \n",
      "1463                NaN                      NaN   \n",
      "1464                NaN                      NaN   \n",
      "1465                NaN                      NaN   \n",
      "1466                NaN                      NaN   \n",
      "1467                NaN                      NaN   \n",
      "1468                NaN                      NaN   \n",
      "1469                NaN                      NaN   \n",
      "1470                NaN                      NaN   \n",
      "1471                NaN                      NaN   \n",
      "1472                NaN                      NaN   \n",
      "1473                NaN                      NaN   \n",
      "1474                NaN                      NaN   \n",
      "1475                NaN                      NaN   \n",
      "1476                NaN                      NaN   \n",
      "1477                NaN                      NaN   \n",
      "1478                NaN                      NaN   \n",
      "1479                NaN                      NaN   \n",
      "1480                NaN                      NaN   \n",
      "1481                NaN                      NaN   \n",
      "1482                NaN                      NaN   \n",
      "1483                NaN                      NaN   \n",
      "1484                NaN                      NaN   \n",
      "1485                NaN                      NaN   \n",
      "1486                NaN                      NaN   \n",
      "1487                NaN                      NaN   \n",
      "1488                NaN                      NaN   \n",
      "1489                NaN                      NaN   \n",
      "1490                NaN                      NaN   \n",
      "1491                NaN                      NaN   \n",
      "\n",
      "      SUPPORT_SERVICES_EXPENDITURE  OTHER_EXPENDITURE  \n",
      "0                         735036.0                NaN  \n",
      "1                         350902.0                NaN  \n",
      "2                        1007732.0                NaN  \n",
      "3                         483488.0                NaN  \n",
      "4                        8520926.0                NaN  \n",
      "5                        1035970.0                NaN  \n",
      "6                        1142600.0                NaN  \n",
      "7                         194915.0                NaN  \n",
      "8                         316679.0                NaN  \n",
      "9                        3410440.0                NaN  \n",
      "10                       1559059.0                NaN  \n",
      "11                        291376.0                NaN  \n",
      "12                        246320.0                NaN  \n",
      "13                       3148849.0                NaN  \n",
      "14                       1478639.0                NaN  \n",
      "15                        800570.0                NaN  \n",
      "16                        708572.0                NaN  \n",
      "17                        817871.0                NaN  \n",
      "18                        986486.0                NaN  \n",
      "19                        317880.0                NaN  \n",
      "20                       1461083.0                NaN  \n",
      "21                       1523068.0                NaN  \n",
      "22                       3321276.0                NaN  \n",
      "23                       1343203.0                NaN  \n",
      "24                        445364.0                NaN  \n",
      "25                       1221397.0                NaN  \n",
      "26                        241644.0                NaN  \n",
      "27                        394690.0                NaN  \n",
      "28                        334685.0                NaN  \n",
      "29                        310285.0                NaN  \n",
      "...                            ...                ...  \n",
      "1462                           NaN                NaN  \n",
      "1463                           NaN                NaN  \n",
      "1464                           NaN                NaN  \n",
      "1465                           NaN                NaN  \n",
      "1466                           NaN                NaN  \n",
      "1467                           NaN                NaN  \n",
      "1468                           NaN                NaN  \n",
      "1469                           NaN                NaN  \n",
      "1470                           NaN                NaN  \n",
      "1471                           NaN                NaN  \n",
      "1472                           NaN                NaN  \n",
      "1473                           NaN                NaN  \n",
      "1474                           NaN                NaN  \n",
      "1475                           NaN                NaN  \n",
      "1476                           NaN                NaN  \n",
      "1477                           NaN                NaN  \n",
      "1478                           NaN                NaN  \n",
      "1479                           NaN                NaN  \n",
      "1480                           NaN                NaN  \n",
      "1481                           NaN                NaN  \n",
      "1482                           NaN                NaN  \n",
      "1483                           NaN                NaN  \n",
      "1484                           NaN                NaN  \n",
      "1485                           NaN                NaN  \n",
      "1486                           NaN                NaN  \n",
      "1487                           NaN                NaN  \n",
      "1488                           NaN                NaN  \n",
      "1489                           NaN                NaN  \n",
      "1490                           NaN                NaN  \n",
      "1491                           NaN                NaN  \n",
      "\n",
      "[1492 rows x 4 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e80db81805c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# fit on data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;31m# access values and vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ece-yusuf-sekoya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ece-yusuf-sekoya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[1;32m--> 381\u001b[1;33m                         copy=self.copy)\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# Handle n_components==None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ece-yusuf-sekoya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ece-yusuf-sekoya\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "A = states_all3\n",
    "print(A)\n",
    "# create the PCA instance\n",
    "pca = PCA(2)\n",
    "# fit on data\n",
    "pca.fit(A)\n",
    "# access values and vectors\n",
    "print(pca.components_)\n",
    "print(pca.explained_variance_)\n",
    "# transform data\n",
    "B = pca.transform(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kovaryans matrisi :\n",
      " [[nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]\n",
      " [nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "sklearn_pca = PCA(n_components=5)\n",
    "\n",
    "X = StandardScaler().fit_transform(A)\n",
    "\n",
    "Xt = X.T\n",
    "Cx = np.cov(Xt)\n",
    "print('Kovaryans matrisi :\\n', Cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
